{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[RNN(tensorflow.ver)]\r\n",
    "tensorflow에서 제공하는 일반적인 RNN layers\r\n",
    "- 기본 RNN : tf.keras.layers.SimpleRNN\r\n",
    "- LSTM : tf.keras.layers.LSTM\r\n",
    "- GRU : tf.keras.layers.GRU\r\n",
    "\r\n",
    "기본적인 tensor shape : [batch, timesteps, feature]\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# tf.keras.SimpleRNN 실습\r\n",
    "# 1. input data의 shape 설정하기\r\n",
    "sequence_len = 16\r\n",
    "feature_dim = 32\r\n",
    "input_sequence = tf.keras.Input(shape = (sequence_len,feature_dim))\r\n",
    "\r\n",
    "print(input_sequence[0:3])\r\n",
    "\r\n",
    "units = 64               # 은닉층 내의 계산에 필요한 노드의 개수\r\n",
    "\r\n",
    "# 2. 모델 객체 생성하기\r\n",
    "simpleRNN = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.SimpleRNN(units),\r\n",
    "    tf.keras.layers.Dense(4,activation = 'softmax')\r\n",
    "])\r\n",
    "\r\n",
    "# 3. 생성한 inputdata를 RNN에 넣어주기\r\n",
    "simpleRNN(input_sequence)\r\n",
    "simpleRNN.summary()\r\n",
    "\r\n",
    "# (+) RNN layer를 여러 층 쌓을 때 return_sequences = True가 꼭 필요하다.\r\n",
    "rnn = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.SimpleRNN(units,return_sequences=True),\r\n",
    "    tf.keras.layers.SimpleRNN(units,return_sequences=True),\r\n",
    "    tf.keras.layers.SimpleRNN(units),\r\n",
    "    tf.keras.layers.Dense(4,activation = 'softmax')\r\n",
    "\r\n",
    "])\r\n",
    "\r\n",
    "rnn(input_sequence)\r\n",
    "rnn.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16, 32), dtype=tf.float32, name=None), name='tf.__operators__.getitem_5/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_5'\")\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_9 (SimpleRNN)     (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 6,468\n",
      "Trainable params: 6,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, 16, 64)            6208      \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 16, 64)            8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_12 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 22,980\n",
      "Trainable params: 22,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# tensorflow 공식문서에 있는 예제 실습\r\n",
    "\r\n",
    "# 1. input data 설정\r\n",
    "inputs = np.random.random([32,10,8]).astype(np.float32)\r\n",
    "print(inputs[0])\r\n",
    "simple_rnn = tf.keras.layers.SimpleRNN(4)\r\n",
    "\r\n",
    "output = simple_rnn(inputs)\r\n",
    "\r\n",
    "# 2. 모델 객체 생성\r\n",
    "simple_rnn = tf.keras.layers.SimpleRNN(\r\n",
    "    4, return_sequences = True, return_state = True\r\n",
    ")\r\n",
    "\r\n",
    "# 3. 모델 학습\r\n",
    "whole_sequence_output, final_state = simple_rnn(inputs)\r\n",
    "print(simple_rnn(inputs))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.91913307 0.6538851  0.40834615 0.52895117 0.20793532 0.5196509\n",
      "  0.41469848 0.6684876 ]\n",
      " [0.5348182  0.32958293 0.47733015 0.7365685  0.51901174 0.7245719\n",
      "  0.47548586 0.21680012]\n",
      " [0.71873176 0.2515378  0.20301442 0.01355956 0.6987435  0.25670996\n",
      "  0.01112409 0.46451432]\n",
      " [0.82648927 0.44578156 0.42941967 0.22714475 0.74694777 0.7054632\n",
      "  0.74405223 0.5350035 ]\n",
      " [0.8202502  0.9505462  0.5945084  0.32007092 0.76203924 0.05417415\n",
      "  0.28965768 0.10499713]\n",
      " [0.6469576  0.6282116  0.10215176 0.84706646 0.18780267 0.9479964\n",
      "  0.8316178  0.3460667 ]\n",
      " [0.7806944  0.22428416 0.5092722  0.43582097 0.20391534 0.62834454\n",
      "  0.72947174 0.17291303]\n",
      " [0.67214465 0.8539699  0.2078268  0.3087864  0.37848392 0.99173135\n",
      "  0.10831729 0.9402645 ]\n",
      " [0.31366062 0.73908156 0.83056784 0.68753093 0.29741064 0.63722306\n",
      "  0.7037061  0.7298062 ]\n",
      " [0.3300683  0.35273647 0.01675337 0.8080716  0.64206123 0.8495237\n",
      "  0.64649117 0.9390194 ]]\n",
      "[<tf.Tensor: shape=(32, 10, 4), dtype=float32, numpy=\n",
      "array([[[-0.57042724, -0.59458053, -0.92046016, -0.6541812 ],\n",
      "        [ 0.52811146, -0.85747623, -0.9317981 ,  0.04088383],\n",
      "        [-0.4799838 , -0.48074862, -0.91152936, -0.80891466],\n",
      "        ...,\n",
      "        [ 0.42381138, -0.46192482, -0.956018  , -0.83281016],\n",
      "        [ 0.6170752 , -0.5253316 , -0.98120487, -0.8350242 ],\n",
      "        [ 0.51610655, -0.4113706 , -0.9449622 , -0.7580533 ]],\n",
      "\n",
      "       [[-0.625361  , -0.5374334 , -0.74994093, -0.48780712],\n",
      "        [ 0.7711724 , -0.76913166, -0.92495763,  0.34162676],\n",
      "        [-0.01168168, -0.29082128, -0.98626465, -0.8790925 ],\n",
      "        ...,\n",
      "        [-0.3701141 , -0.02084263, -0.95609415, -0.7333607 ],\n",
      "        [ 0.6394335 , -0.86577123, -0.4549965 , -0.27060986],\n",
      "        [-0.5318836 , -0.30346873, -0.97012645, -0.7700295 ]],\n",
      "\n",
      "       [[-0.11591782, -0.682786  , -0.91565144, -0.5119662 ],\n",
      "        [ 0.4087688 , -0.739795  , -0.92471766, -0.49517775],\n",
      "        [-0.18819606, -0.40849003, -0.965551  , -0.6847544 ],\n",
      "        ...,\n",
      "        [ 0.7466878 , -0.4259421 , -0.92083913, -0.7584414 ],\n",
      "        [ 0.34547833, -0.21463917, -0.98585707, -0.94160944],\n",
      "        [ 0.87990564, -0.4303365 , -0.9560105 , -0.83435875]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.69979024, -0.7824597 , -0.89898765, -0.09987808],\n",
      "        [ 0.05060292, -0.9479172 , -0.9537929 , -0.24197933],\n",
      "        [ 0.16250898, -0.47430465, -0.97730863, -0.65968615],\n",
      "        ...,\n",
      "        [ 0.5595112 ,  0.12739044, -0.9397929 , -0.92174685],\n",
      "        [ 0.51254654, -0.03440224, -0.9002712 , -0.89586484],\n",
      "        [-0.2278246 , -0.64655113, -0.629128  , -0.9040686 ]],\n",
      "\n",
      "       [[-0.5959198 , -0.84627116, -0.9406964 , -0.36632708],\n",
      "        [ 0.39552292, -0.89826584, -0.94665915,  0.459875  ],\n",
      "        [ 0.21465564, -0.7379775 , -0.95859474, -0.39369106],\n",
      "        ...,\n",
      "        [-0.03680473, -0.682866  , -0.9475796 , -0.89616936],\n",
      "        [ 0.5366968 , -0.59113276, -0.9599046 , -0.5542503 ],\n",
      "        [ 0.32436258, -0.7374441 , -0.9623399 , -0.8589451 ]],\n",
      "\n",
      "       [[-0.51383144, -0.5072335 , -0.6441314 , -0.31659812],\n",
      "        [-0.08090789, -0.8138645 , -0.9862838 , -0.30177215],\n",
      "        [ 0.17506963, -0.80108565, -0.99034786, -0.7652735 ],\n",
      "        ...,\n",
      "        [ 0.5776972 , -0.6153225 , -0.94036967, -0.6687623 ],\n",
      "        [ 0.6981032 , -0.3791581 , -0.95101523, -0.76085424],\n",
      "        [-0.01277037, -0.67157304, -0.854561  , -0.5642959 ]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
      "array([[ 0.51610655, -0.4113706 , -0.9449622 , -0.7580533 ],\n",
      "       [-0.5318836 , -0.30346873, -0.97012645, -0.7700295 ],\n",
      "       [ 0.87990564, -0.4303365 , -0.9560105 , -0.83435875],\n",
      "       [ 0.1081713 , -0.9097714 , -0.90585613, -0.36921963],\n",
      "       [ 0.89526004, -0.6021495 , -0.94161296, -0.8186878 ],\n",
      "       [-0.1175881 , -0.22603692, -0.8919266 , -0.8987592 ],\n",
      "       [ 0.11250816, -0.5575576 , -0.86060125, -0.792578  ],\n",
      "       [ 0.77812034, -0.51652753, -0.9636768 , -0.807548  ],\n",
      "       [ 0.01626729, -0.6217732 , -0.79533535, -0.8204524 ],\n",
      "       [ 0.468846  , -0.5111659 , -0.5157306 , -0.65382123],\n",
      "       [ 0.32906812, -0.31964886, -0.9531889 , -0.8735262 ],\n",
      "       [ 0.53022885, -0.03669565, -0.8334025 , -0.8062081 ],\n",
      "       [-0.87759465, -0.44298053, -0.98444897, -0.81071913],\n",
      "       [ 0.22844742, -0.7886999 , -0.79415303, -0.7605268 ],\n",
      "       [ 0.07480218, -0.0418478 , -0.9781068 , -0.9273714 ],\n",
      "       [-0.31552622, -0.79378486, -0.68547004, -0.43716288],\n",
      "       [ 0.64344305, -0.4318707 , -0.921936  , -0.71754944],\n",
      "       [-0.04895561, -0.65730345, -0.96197534, -0.92722046],\n",
      "       [ 0.22269037, -0.14522868, -0.97262096, -0.9128915 ],\n",
      "       [ 0.32880744, -0.4386973 , -0.84560126, -0.45534724],\n",
      "       [ 0.72042507, -0.6362446 , -0.96294075, -0.22950996],\n",
      "       [-0.25848353, -0.78528607, -0.97135967, -0.29886234],\n",
      "       [ 0.4769823 , -0.00449142, -0.9319441 , -0.24775513],\n",
      "       [ 0.83812314, -0.20605901, -0.9770602 , -0.7633204 ],\n",
      "       [ 0.47163165, -0.26917255, -0.89067125, -0.651658  ],\n",
      "       [ 0.5763769 , -0.38128716, -0.96698916, -0.5273208 ],\n",
      "       [ 0.8321123 , -0.7014147 , -0.9829528 , -0.34685495],\n",
      "       [ 0.7514704 , -0.7813309 , -0.91455907, -0.71898174],\n",
      "       [ 0.783305  ,  0.08876708, -0.9758952 , -0.7824001 ],\n",
      "       [-0.2278246 , -0.64655113, -0.629128  , -0.9040686 ],\n",
      "       [ 0.32436258, -0.7374441 , -0.9623399 , -0.8589451 ],\n",
      "       [-0.01277037, -0.67157304, -0.854561  , -0.5642959 ]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# tensorflow SimpleRNN 실습 - (2)\r\n",
    "# 1. 임의의 입력 데이터 생성하기\r\n",
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\r\n",
    "print(np.shape(train_X))  # 단어의 벡터 차원은 5이고, 문장의 길이는 => 즉 4번의 시점이 존재\r\n",
    "\r\n",
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\r\n",
    "train_X = np.array(train_X, dtype = np.float32)\r\n",
    "\r\n",
    "print(train_X.shape)\r\n",
    "\r\n",
    "# 2. 모델 객체 생성\r\n",
    "rnn2 = tf.keras.layers.SimpleRNN(3)\r\n",
    "hidden_state = rnn2(train_X)\r\n",
    "\r\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\r\n",
    "\r\n",
    "rnn3 = tf.keras.layers.SimpleRNN(3, return_sequences = True)\r\n",
    "hidden_state2 = rnn3(train_X)\r\n",
    "\r\n",
    "\r\n",
    "# (+) return_sequences와 return_state\r\n",
    "# 1. return_sequences = True \r\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state2, hidden_state2.shape))\r\n",
    "# reqeunces_sequences = True : 모든 시점에 대해서 은닉상태의 값을 출력하므로 (1,4,3)크기의 텐서 출력\r\n",
    "\r\n",
    "# 2. return_state = True \r\n",
    "rnn4 = tf.keras.layers.SimpleRNN(3, return_sequences=True, return_state=True)\r\n",
    "hidden_states3, last_state3 = rnn4(train_X)\r\n",
    "\r\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states3, hidden_states3.shape))\r\n",
    "print('last hidden state : {}, shape: {}'.format(last_state3, last_state3.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 5)\n",
      "(1, 4, 5)\n",
      "hidden state : [[ 0.11190259  0.7635743  -0.7383125 ]], shape : (1, 3)\n",
      "hidden state : [[[-0.99982095  0.99990684 -0.9928325 ]\n",
      "  [-0.9963161   0.9901295  -0.9945824 ]\n",
      "  [ 0.07190195  0.9255673  -0.9006116 ]\n",
      "  [-0.96646833 -0.31942895 -0.79504144]]], shape : (1, 4, 3)\n",
      "hidden states : [[[-0.37950125 -0.99998146  0.8538579 ]\n",
      "  [-0.90090996 -0.99509317  0.40671185]\n",
      "  [-0.1903357  -0.97840416  0.93146   ]\n",
      "  [-0.9228084  -0.3114125  -0.7664354 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[-0.9228084 -0.3114125 -0.7664354]], shape: (1, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# 심화) LSTM 실습\r\n",
    "\r\n",
    "lstm = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.LSTM(units),\r\n",
    "    tf.keras.layers.Dense(4, activation = 'softmax')\r\n",
    "])  \r\n",
    "\r\n",
    "lstm(input_sequence)\r\n",
    "lstm.summary()\r\n",
    "\r\n",
    "# (+) return_state = True로 설정하면 LSTM의 마지막 cell state와 hidden state를 모두 return\r\n",
    "# tf.keras.Sequential에서는 각 layer의 output이 1개일때만 사용가능\r\n",
    "\r\n",
    "# LSTM 클래스에 tf.keras.Model을 상속\r\n",
    "class LSTM(tf.keras.Model):\r\n",
    "    def __init__(self):\r\n",
    "        super(LSTM,self).__init__()\r\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(units, return_sequences = True, return_state = True)\r\n",
    "        self.dense = tf.keras.layers.Dense(4, activation = 'softmax')\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        whole_seq_output,final_hidden_state, final_cell_state = self.lstm_layer(inputs)\r\n",
    "\r\n",
    "        # shape를 출력\r\n",
    "        print(\"whole_seq_ouput : \", whole_seq_output.shape)\r\n",
    "        print(\"final_hidden_state : \", final_hidden_state.shape)\r\n",
    "        print(\"final_cell_state : \",final_cell_state.shape)\r\n",
    "\r\n",
    "        output_prob = self.dense(whole_seq_output)\r\n",
    "        return output_prob\r\n",
    "\r\n",
    "lstm = LSTM()\r\n",
    "lstm(input_sequence)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 25,092\n",
      "Trainable params: 25,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "whole_seq_ouput :  (None, 16, 64)\n",
      "final_hidden_state :  (None, 64)\n",
      "final_cell_state :  (None, 64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16, 4) dtype=float32 (created by layer 'lstm_9')>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 심화2 ) GRU 실습"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}